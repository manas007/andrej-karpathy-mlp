{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. \n",
    "# Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em m\n",
      "mm a\n"
     ]
    }
   ],
   "source": [
    "#trigram languague model. looking at 2 chars and predict third\n",
    "for w in words[:1]:\n",
    "    for ch1, ch2, ch3 in zip(w, w[1:] , w[2:]):\n",
    "        print(ch1+ch2, ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".e m\n",
      "em m\n",
      "mm a\n",
      "ma .\n"
     ]
    }
   ],
   "source": [
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.'] # breaks the word into list of characters. \".\" donates either the start or end position\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        print(ch1+ch2, ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        trigram = (ch1+ch2 , ch3)\n",
    "        b[trigram] = b.get(trigram , 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ah', '.'), 1714),\n",
       " (('na', '.'), 1673),\n",
       " (('an', '.'), 1509),\n",
       " (('on', '.'), 1503),\n",
       " (('.m', 'a'), 1453)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(), key = lambda kv : -kv[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(''.join(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s : i+1 for i , s in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {k : v for k , v in sorted(stoi.items() , key = lambda kv : kv[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {v : k for k , v in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '.',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27, 27), dtype=torch.int32) # a 3 dim matrix to keep count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.'] # breaks the word into list of characters\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        N[ix1, ix2, ix3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float() # change N to float \n",
    "P /= P.sum(dim=2, keepdim=True) # probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "drawn = torch.multinomial(P[(0,1)], num_samples = 1, replacement = True, generator = g) \n",
    "itos[drawn.item()] # given characters '.' and 'a' , predicted next word is'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quia.\n",
      "yu.\n",
      "quinslyntien.\n",
      "nolliahi.\n",
      "ha.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix1 , ix2 = 0 , 0 # start token\n",
    "    \n",
    "    while True:\n",
    "        p = P[ix1, ix2]\n",
    "        draw = torch.multinomial(p, num_samples = 1 , replacement = True, generator = g).item()\n",
    "        ix1 = ix2 \n",
    "        ix2 = draw\n",
    "        out.append(itos[draw])\n",
    "\n",
    "        if ix2 == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        p = P[ix1, ix2, ix3]\n",
    "        logprob = torch.log(p)\n",
    "        log_likelihood.append(logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0927)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll = -sum(log_likelihood)/len(log_likelihood)\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will approach using Nueral Network (NN)\n",
    "\n",
    "# create training set of all trigrams (x,y). let's take example of one work. emma\n",
    "xs , ys = [] , []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.'] # breaks the word into list of characters\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append((ix1,ix2))\n",
    "        ys.append(ix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5), (5, 13), (13, 13), (13, 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5],\n",
       "        [ 5, 13],\n",
       "        [13, 13],\n",
       "        [13,  1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = torch.tensor(xs)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 13, 1, 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's one hot encode the indexes\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()\n",
    "xenc = xenc.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4161e+00,  1.1427e+00,  1.6257e-01,  ..., -3.6003e-01,\n",
       "         -8.2119e-01, -1.5632e+00],\n",
       "        [-7.1959e-02, -3.6383e-01,  7.4463e-01,  ...,  1.1880e+00,\n",
       "          2.4414e+00,  1.5129e-01],\n",
       "        [-4.3048e-01,  1.0561e+00,  7.9576e-01,  ..., -1.3768e+00,\n",
       "         -2.6347e+00, -1.2294e+00],\n",
       "        ...,\n",
       "        [ 1.4806e+00, -2.3179e-01, -2.0186e+00,  ...,  3.5723e-02,\n",
       "          1.1400e+00, -2.8680e-01],\n",
       "        [-2.2949e-02,  6.5543e-01,  1.1687e+00,  ..., -2.0022e-03,\n",
       "         -1.0169e-01, -1.2109e+00],\n",
       "        [ 7.0296e-01,  3.0037e+00, -7.6926e-01,  ...,  7.2339e-01,\n",
       "          1.3037e+00,  7.2492e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147983647)\n",
    "W = torch.randn((54 , 27) , requires_grad=True)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 54]), torch.Size([54, 27]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape , W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xenc @ W # log counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.3195e-04, 8.2283e-02, 7.9317e-03, 3.3255e-02, 1.2344e-01, 8.1608e-02,\n",
       "         3.1106e-02, 8.7547e-03, 2.3864e-02, 3.2929e-03, 1.1683e-02, 1.2105e-02,\n",
       "         1.7112e-03, 1.9704e-01, 5.7410e-03, 2.4205e-02, 4.6082e-02, 6.5915e-03,\n",
       "         7.8675e-03, 2.0198e-02, 2.1741e-03, 5.9786e-02, 3.5171e-02, 6.6405e-02,\n",
       "         9.6034e-02, 2.5800e-03, 8.3640e-03],\n",
       "        [5.2415e-03, 9.1430e-03, 4.2676e-02, 1.5511e-02, 3.6094e-02, 6.5416e-02,\n",
       "         6.8232e-02, 1.7006e-03, 1.0237e-02, 8.9780e-03, 1.9050e-02, 5.4922e-02,\n",
       "         1.0665e-02, 2.2260e-03, 9.4412e-02, 1.3869e-03, 8.0612e-03, 2.0505e-01,\n",
       "         1.5228e-03, 9.5389e-03, 2.2229e-02, 3.2209e-02, 1.6361e-01, 1.6322e-02,\n",
       "         2.0596e-02, 6.1828e-02, 1.3146e-02],\n",
       "        [2.1156e-04, 1.7804e-03, 8.9477e-03, 1.9468e-02, 1.2605e-02, 3.6700e-02,\n",
       "         4.2149e-02, 1.6534e-02, 1.9048e-02, 7.2659e-02, 3.5635e-02, 2.4492e-02,\n",
       "         5.4557e-03, 1.8007e-02, 3.1899e-02, 3.6672e-03, 6.1302e-02, 2.4708e-01,\n",
       "         1.6010e-03, 3.4526e-02, 2.1483e-02, 1.2633e-02, 2.1423e-01, 2.0038e-02,\n",
       "         6.3012e-03, 1.7233e-02, 1.4309e-02],\n",
       "        [3.2643e-04, 7.8818e-03, 1.9663e-02, 3.1800e-02, 1.4676e-02, 8.4485e-03,\n",
       "         9.8363e-03, 5.1128e-02, 2.3297e-02, 9.5351e-02, 2.6212e-01, 1.1445e-01,\n",
       "         6.8656e-03, 4.9616e-03, 3.3976e-03, 6.3634e-02, 3.4633e-02, 6.6087e-03,\n",
       "         1.6321e-03, 9.1159e-02, 3.9918e-02, 1.0358e-02, 2.9580e-02, 4.4144e-02,\n",
       "         3.8596e-03, 1.9177e-02, 1.0947e-03]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = counts / counts.sum(1 , keepdims = True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set of all trigrams (x,y). \n",
    "xs , ys = [] , []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.'] # breaks the word into list of characters\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append((ix1,ix2))\n",
    "        ys.append(ix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196113, 54]), torch.Size([196113]), 196113)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's one hot encode the indexes\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()\n",
    "xenc = xenc.flatten(1)\n",
    "number_of_inputs = xs.shape[0]\n",
    "xenc.shape , ys.shape, number_of_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27 * 2, 27), generator=g, requires_grad=True) # need to pass requires grad = True so that torch knows we want\n",
    "# to calculte the grad of this leaf tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1959710121154785\n",
      "3.365379571914673\n",
      "3.049534320831299\n",
      "2.8784797191619873\n",
      "2.7739577293395996\n",
      "2.7012393474578857\n",
      "2.6454999446868896\n",
      "2.601283550262451\n",
      "2.5652339458465576\n",
      "2.535409927368164\n",
      "2.51039719581604\n",
      "2.4892263412475586\n",
      "2.4711148738861084\n",
      "2.455474853515625\n",
      "2.4418272972106934\n",
      "2.4298088550567627\n",
      "2.4191300868988037\n",
      "2.4095728397369385\n",
      "2.4009628295898438\n",
      "2.3931643962860107\n",
      "2.38606595993042\n",
      "2.3795783519744873\n",
      "2.373626708984375\n",
      "2.368147850036621\n",
      "2.3630881309509277\n",
      "2.358403205871582\n",
      "2.354053020477295\n",
      "2.3500046730041504\n",
      "2.3462281227111816\n",
      "2.342698097229004\n",
      "2.3393921852111816\n",
      "2.3362908363342285\n",
      "2.3333756923675537\n",
      "2.330632209777832\n",
      "2.3280460834503174\n",
      "2.3256044387817383\n",
      "2.3232970237731934\n",
      "2.321112632751465\n",
      "2.3190431594848633\n",
      "2.317080020904541\n",
      "2.3152151107788086\n",
      "2.3134419918060303\n",
      "2.311753988265991\n",
      "2.3101463317871094\n",
      "2.308612585067749\n",
      "2.307147979736328\n",
      "2.3057494163513184\n",
      "2.3044114112854004\n",
      "2.3031303882598877\n",
      "2.301903486251831\n",
      "2.300726890563965\n",
      "2.2995975017547607\n",
      "2.298513650894165\n",
      "2.297471284866333\n",
      "2.296468734741211\n",
      "2.295503854751587\n",
      "2.294574499130249\n",
      "2.2936789989471436\n",
      "2.2928152084350586\n",
      "2.2919814586639404\n",
      "2.2911763191223145\n",
      "2.290398597717285\n",
      "2.289646625518799\n",
      "2.28891921043396\n",
      "2.288215398788452\n",
      "2.2875335216522217\n",
      "2.2868733406066895\n",
      "2.2862329483032227\n",
      "2.2856123447418213\n",
      "2.2850098609924316\n",
      "2.2844254970550537\n",
      "2.283857583999634\n",
      "2.283306121826172\n",
      "2.2827701568603516\n",
      "2.2822489738464355\n",
      "2.2817423343658447\n",
      "2.2812492847442627\n",
      "2.280768871307373\n",
      "2.280301809310913\n",
      "2.279846668243408\n",
      "2.2794029712677\n",
      "2.2789711952209473\n",
      "2.2785494327545166\n",
      "2.2781383991241455\n",
      "2.2777373790740967\n",
      "2.277346611022949\n",
      "2.2769646644592285\n",
      "2.2765917778015137\n",
      "2.2762274742126465\n",
      "2.275872230529785\n",
      "2.275524616241455\n",
      "2.2751851081848145\n",
      "2.274853467941284\n",
      "2.274528741836548\n",
      "2.2742109298706055\n",
      "2.2739005088806152\n",
      "2.2735965251922607\n",
      "2.2732994556427\n",
      "2.273008346557617\n",
      "2.272723436355591\n"
     ]
    }
   ],
   "source": [
    "# gradient descent, 100 iterations\n",
    "for k in range(100):\n",
    "  # forward pass\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(number_of_inputs), ys].log().mean() + 0.01*(W**2).mean() # regularization added\n",
    "  print(loss.item())\n",
    "    \n",
    "  # backward pass\n",
    "  W.grad = None # set gradient to zero\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nor.\n",
      "ays.\n",
      "nileyloryear.\n",
      "erellais.\n",
      "ah.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix1 , ix2 = 0 , 0 # start token\n",
    "    \n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
    "        xenc_flattened = xenc.flatten(0)\n",
    "        logits = xenc_flattened @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts/counts.sum(0, keepdims=True)\n",
    "        ix1 = ix2 \n",
    "        ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix2])\n",
    "\n",
    "        if ix2 == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E02\n",
    "#split up the dataset randomly into 80% train set, 10% dev set, 10% test set. \n",
    "#Train the bigram and trigram models only on the training set.\n",
    "#Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrigramDataset(words):\n",
    "    xs , ys = [] , []\n",
    "    for w in words:\n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2, ch3 in zip(chs , chs[1:] , chs[2:]):\n",
    "            ix1 = stoi[ch1]\n",
    "            ix2 = stoi[ch2]\n",
    "            ix3 = stoi[ch3]\n",
    "            xs.append((ix1, ix2))\n",
    "            ys.append(ix3)\n",
    "    \n",
    "    xs = F.one_hot(torch.tensor(xs), num_classes = 27).float()\n",
    "    xs = xs.flatten(1)\n",
    "    return torch.tensor(xs) , torch.tensor(ys)\n",
    "\n",
    "def createBigramDataset(words):\n",
    "    xs , ys = [] , []\n",
    "    for w in words:\n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2 in zip(chs , chs[1:]):\n",
    "            ix1 = stoi[ch1]\n",
    "            ix2 = stoi[ch2]\n",
    "            xs.append(ix1)\n",
    "            ys.append(ix2)\n",
    "            \n",
    "    xs = F.one_hot(torch.tensor(xs), num_classes = 27).float()\n",
    "    return torch.tensor(xs) , torch.tensor(ys)\n",
    "\n",
    "def createTrainDevAndTestSet(xs, ys):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    train_set_idxs, dev_set_idxs, test_set_idxs = torch.utils.data.random_split(range(xs.shape[0]), [0.8 , 0.1 , 0.1], generator=g)\n",
    "    \n",
    "    train_set_idxs = torch.tensor(train_set_idxs)\n",
    "    dev_set_idxs = torch.tensor(dev_set_idxs)\n",
    "    test_set_idxs = torch.tensor(test_set_idxs)\n",
    "    \n",
    "    x_train , y_train = xs[train_set_idxs] , ys[train_set_idxs]\n",
    "    x_dev, y_dev = xs[dev_set_idxs] , ys[dev_set_idxs]\n",
    "    x_test, y_test = xs[test_set_idxs] , ys[test_set_idxs]\n",
    "    \n",
    "    return x_train , y_train , x_dev, y_dev, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "xs , ys = createTrigramDataset(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train , x_dev, y_dev, x_test, y_test = createTrainDevAndTestSet(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([156891, 54]) torch.Size([156891])\n",
      "torch.Size([19611, 54]) torch.Size([19611])\n",
      "torch.Size([19611, 54]) torch.Size([19611])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape , y_train.shape)\n",
    "print(x_dev.shape , y_dev.shape)\n",
    "print(x_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTrigram(X, y , epochs , lr , reg):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    W = torch.randn((27 * 2, 27), generator=g, requires_grad=True) # need to pass requires grad = True so that torch knows we want\n",
    "    # to calculte the grad of this leaf tensor\n",
    "    number_of_inputs = X.shape[0]\n",
    "    # gradient descent, 100 iterations\n",
    "    for k in range(epochs):\n",
    "        # forward pass\n",
    "        logits = X @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "        loss = -probs[torch.arange(number_of_inputs), y].log().mean() + reg*(W**2).mean() # regularization added\n",
    "        \n",
    "        #print(loss.item())\n",
    "        loss_hist.append(loss)\n",
    "        # backward pass\n",
    "        W.grad = None # set gradient to zero\n",
    "        loss.backward()\n",
    "  \n",
    "        # update\n",
    "        W.data += -lr * W.grad\n",
    "    \n",
    "    return W , loss.item()\n",
    "\n",
    "\n",
    "def trainBigram(X, y , epochs , lr , reg):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    W = torch.randn((27 , 27), generator=g, requires_grad=True) # need to pass requires grad = True so that torch knows we want\n",
    "    # to calculate the grad of this leaf tensor\n",
    "    number_of_inputs = X.shape[0]\n",
    "    # gradient descent, 100 iterations\n",
    "    for k in range(epochs):\n",
    "        # forward pass\n",
    "        logits = X @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "        loss = -probs[torch.arange(number_of_inputs), y].log().mean() + reg*(W**2).mean() # regularization added\n",
    "        \n",
    "        #print(loss.item())\n",
    "        loss_hist.append(loss)\n",
    "        # backward pass\n",
    "        W.grad = None # set gradient to zero\n",
    "        loss.backward()\n",
    "  \n",
    "        # update\n",
    "        W.data += -lr * W.grad\n",
    "    \n",
    "    return W , loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_trigram , loss = trainTrigram(x_train , y_train, 100 , 50 , 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model , X , y):\n",
    "    logits = X @ model\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims = True)\n",
    "    loss = -probs[torch.arange(X.shape[0]), y].log().mean().item()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev set loss :  2.2833502292633057\n",
      "test set loss :  2.2709267139434814\n"
     ]
    }
   ],
   "source": [
    "loss_on_dev_set = evaluate_loss(W_trigram , x_dev , y_dev)\n",
    "loss_on_test_set = evaluate_loss(W_trigram , x_test , y_test)\n",
    "\n",
    "print('dev set loss : ' , loss_on_dev_set)\n",
    "print('test set loss : ' , loss_on_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "xs , ys = createBigramDataset(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , y_train , x_dev, y_dev, x_test, y_test = createTrainDevAndTestSet(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182517, 27]) torch.Size([182517])\n",
      "torch.Size([22815, 27]) torch.Size([22815])\n",
      "torch.Size([22814, 27]) torch.Size([22814])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape , y_train.shape)\n",
    "print(x_dev.shape , y_dev.shape)\n",
    "print(x_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_bigram , loss_bigram = trainBigram(x_train , y_train, 100 , 50 , 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.586700677871704"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev set loss :  2.5082480907440186\n",
      "test set loss :  2.510897636413574\n"
     ]
    }
   ],
   "source": [
    "loss_on_dev_set = evaluate_loss(W_bigram , x_dev , y_dev)\n",
    "loss_on_test_set = evaluate_loss(W_bigram , x_test , y_test)\n",
    "\n",
    "print('dev set loss : ' , loss_on_dev_set)\n",
    "print('test set loss : ' , loss_on_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E03:\n",
    "#Use the dev set to tune the strength of smoothing (or regularization) for the trigram model - \n",
    "#i.e. try many possibilities and see which one works best based on the dev set loss. \n",
    "#What patterns can you see in the train and dev set loss as you tune this strength?\n",
    "#Take the best setting of the smoothing and evaluate on the test set once and at the end. \n",
    "#How good of a loss do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009999999776482582,\n",
       " 0.035789474844932556,\n",
       " 0.06157895177602768,\n",
       " 0.0873684212565422,\n",
       " 0.11315789818763733,\n",
       " 0.13894738256931305,\n",
       " 0.16473685204982758,\n",
       " 0.1905263364315033,\n",
       " 0.21631580591201782,\n",
       " 0.24210527539253235,\n",
       " 0.2678947448730469,\n",
       " 0.2936842441558838,\n",
       " 0.3194737136363983,\n",
       " 0.34526318311691284,\n",
       " 0.37105265259742737,\n",
       " 0.3968421220779419,\n",
       " 0.42263156175613403,\n",
       " 0.44842106103897095,\n",
       " 0.4742105305194855,\n",
       " 0.5]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_list = torch.linspace(0.01, 0.5, 20).tolist()\n",
    "reg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "xs , ys = createTrigramDataset(words)\n",
    "\n",
    "x_train , y_train , x_dev, y_dev, x_test, y_test = createTrainDevAndTestSet(xs,ys)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for reg in reg_list:\n",
    "    model , train_loss = trainTrigram(x_train, y_train , 100 , 50 , reg)\n",
    "    val_loss = evaluate_loss(model, x_dev , y_dev)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "plt.plot(reg_list , train_losses)\n",
    "plt.plot(reg_list , val_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('regularization parameter')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model , best_loss = trainTrigram(x_train, y_train , 100 , 50 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2631618976593018"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.344167470932007\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_loss(model, x_dev , y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.331618070602417\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_loss(model, x_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We saw that our 1-hot vectors merely select a row of W, \n",
    "#so producing these vectors explicitly feels wasteful.\n",
    "#Can you delete our use of F.one_hot in favor of simply indexing into rows of W?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs , ys = [] , []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs , chs[1:] , chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(ix3)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27 * 2 , 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196113, 2]), torch.Size([54, 27]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape , W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "xs_oneh = F.one_hot(torch.tensor(xs), num_classes = 27).float()\n",
    "xs_oneh = xs_oneh.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5352,  0.2418, -0.2616,  ..., -1.6675,  0.6432,  1.0764],\n",
       "        [ 0.8098,  1.5744,  0.0988,  ..., -0.9052, -0.2371,  3.2653],\n",
       "        [ 0.5310,  1.1447,  0.4153,  ...,  1.0670,  2.4894,  1.5959],\n",
       "        ...,\n",
       "        [ 0.3543,  0.8678,  0.0411,  ..., -1.8267,  1.9362, -0.1628],\n",
       "        [ 0.4902, -1.4578,  0.0746,  ..., -0.0480,  0.8478, -1.1147],\n",
       "        [ 1.5952, -0.6920, -0.7784,  ..., -1.5724,  0.8434, -0.9350]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_oneh @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13,  ..., 26, 25, 26])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  ..., 25, 26, 24])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5352,  0.2418, -0.2616,  ..., -1.6675,  0.6432,  1.0764],\n",
       "        [ 0.8098,  1.5744,  0.0988,  ..., -0.9052, -0.2371,  3.2653],\n",
       "        [ 0.5310,  1.1447,  0.4153,  ...,  1.0670,  2.4894,  1.5959],\n",
       "        ...,\n",
       "        [ 0.3543,  0.8678,  0.0411,  ..., -1.8267,  1.9362, -0.1628],\n",
       "        [ 0.4902, -1.4578,  0.0746,  ..., -0.0480,  0.8478, -1.1147],\n",
       "        [ 1.5952, -0.6920, -0.7784,  ..., -1.5724,  0.8434, -0.9350]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[xs[: , 0]] + W[xs[: , 1]+27] # first half is first character , second half for the second character"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
